import os
import time
import json
import logging
from datetime import datetime
from typing import Dict, List, Optional
from urllib.parse import urlparse

import requests
from facebook_scraper import get_posts
from requests.exceptions import HTTPError, RequestException

# ----------------- –õ–û–ì–ò -----------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - fb_parser - %(levelname)s - %(message)s",
)
log = logging.getLogger("fb_parser")

# ----------------- –ö–û–ù–§–ò–ì –ß–ï–†–ï–ó ENV -----------------

# –Ω–∞–ø—Ä–∏–º–µ—Ä: https://miniapptg-production-caaa.up.railway.app
API_BASE_URL = os.getenv("API_BASE_URL")
API_SECRET = os.getenv("API_SECRET", "mvp-secret-key-2024")

# –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é), –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω–æ ‚Äî –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π —Å–ø–∏—Å–æ–∫
KEYWORDS_ENV = os.getenv(
    "KEYWORDS",
    "–≤–∞–∫–∞–Ω—Å–∏—è,—Ä–∞–±–æ—Ç–∞,job,hiring,remote,developer,–ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç",
)
KEYWORDS: List[str] = [k.strip().lower() for k in KEYWORDS_ENV.split(",") if k.strip()]

# –ö—É–∫–∏ –¥–ª—è Facebook –≤ JSON-—Ñ–æ—Ä–º–∞—Ç–µ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π FB_COOKIES_JSON
# –ø—Ä–∏–º–µ—Ä:
# {"c_user": "...", "xs": "...", ...}
FB_COOKIES_JSON = os.getenv("FB_COOKIES_JSON")
COOKIES: Optional[Dict[str, str]] = None
if FB_COOKIES_JSON:
    try:
        COOKIES = json.loads(FB_COOKIES_JSON)
        log.info("Cookies –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ FB_COOKIES_JSON")
    except json.JSONDecodeError:
        log.error("‚ùå –ù–µ –º–æ–≥—É —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å FB_COOKIES_JSON ‚Äî –ø—Ä–æ–≤–µ—Ä—å —Ñ–æ—Ä–º–∞—Ç JSON")
        COOKIES = None
else:
    log.warning("‚ö†Ô∏è FB_COOKIES_JSON –Ω–µ –∑–∞–¥–∞–Ω ‚Äî Facebook, —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, –ø–æ–∫–∞–∂–µ—Ç –∫–∞–ø—á—É/–ª–æ–≥–∏–Ω")

if not API_BASE_URL:
    log.error("‚ùå –ù–µ –∑–∞–¥–∞–Ω API_BASE_URL ‚Äî –±–µ–∑ –Ω–µ–≥–æ –ø–∞—Ä—Å–µ—Ä –Ω–µ –∑–Ω–∞–µ—Ç, –∫—É–¥–∞ —Å–ª–∞—Ç—å –≤–∞–∫–∞–Ω—Å–∏–∏")
    # –Ω–æ –Ω–µ –≤—ã—Ö–æ–¥–∏–º, –≤–¥—Ä—É–≥ –∫—Ç–æ-—Ç–æ –ø–æ—Å—Ç–∞–≤–∏—Ç –ø–æ—Ç–æ–º

# ----------------- –£–¢–ò–õ–ò–¢–´ -----------------


def normalize_group_identifier(group_link: str) -> Optional[str]:
    """
    –ü—Ä–µ–≤—Ä–∞—â–∞–µ—Ç —Å—Å—ã–ª–∫—É/–∏–º—è –≥—Ä—É–ø–ø—ã –≤ —Ç–æ, —á—Ç–æ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å –≤ facebook_scraper.get_posts(group=...).

    –ü—Ä–∏–º–µ—Ä—ã:
      "https://www.facebook.com/groups/ProjectAmazon" -> "ProjectAmazon"
      "https://facebook.com/groups/123456789"        -> "123456789"
      "ProjectAmazon"                                -> "ProjectAmazon"
    """
    if not group_link:
        return None

    group_link = group_link.strip()

    # –ï—Å–ª–∏ –ø—Ä–æ—Å—Ç–æ ID –∏–ª–∏ –∏–º—è
    if not group_link.startswith("http://") and not group_link.startswith("https://"):
        return group_link.strip("/")

    parsed = urlparse(group_link)
    path = (parsed.path or "").strip("/")  # "groups/ProjectAmazon" –∏–ª–∏ "groups/123456789"

    parts = path.split("/")
    # –û–∂–∏–¥–∞–µ–º—ã–π –≤–∞—Ä–∏–∞–Ω—Ç: ["groups", "ProjectAmazon"]
    if len(parts) >= 2 and parts[0] == "groups":
        return parts[1]

    # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π ‚Äî –±–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–µ–≥–º–µ–Ω—Ç
    if parts:
        return parts[-1]

    return None


def matches_keywords(text: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤.
    """
    if not text:
        return False
    lower = text.lower()
    return any(k in lower for k in KEYWORDS)


# ----------------- –†–ê–ë–û–¢–ê –° API –ú–ò–ù–ò–ê–ü–ü–ê -----------------


def get_fb_groups() -> List[Dict]:
    """
    –ó–∞–±–∏—Ä–∞–µ–º —Å–ø–∏—Å–æ–∫ –≥—Ä—É–ø–ø –∏–∑ –º–∏–Ω–∏–∞–ø–ø–∞: GET {API_BASE_URL}/api/groups

    –ú–∏–Ω–∏–∞–ø–ø –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏ Facebook, –∏ Telegram –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –≤ –æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü–µ fb_groups.
    –ó–¥–µ—Å—å –º—ã –æ—Å—Ç–∞–≤–ª—è–µ–º –¢–û–õ–¨–ö–û Facebook-–≥—Ä—É–ø–ø—ã:

      - group_id —Å–æ–¥–µ—Ä–∂–∏—Ç 'facebook.com' –∏–ª–∏ 'fb.com'
      - –ø—Ä–∏ —ç—Ç–æ–º –ù–ï —Å–æ–¥–µ—Ä–∂–∏—Ç 't.me' (—Ç–µ–ª–µ–≥–∞) –∏ 'telegram.me'.
    """
    if not API_BASE_URL:
        log.error("‚ùå API_BASE_URL –Ω–µ –∑–∞–¥–∞–Ω, –Ω–µ –º–æ–≥—É –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≥—Ä—É–ø–ø.")
        return []

    url = API_BASE_URL.rstrip("/") + "/api/groups"
    log.info(f"API –≥—Ä—É–ø–ø: {url}")
    try:
        resp = requests.get(url, timeout=30)
        resp.raise_for_status()
    except RequestException as e:
        log.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –≥—Ä—É–ø–ø—ã: {e}")
        return []

    try:
        data = resp.json()
    except ValueError:
        log.error("‚ùå –ù–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –≥—Ä—É–ø–ø")
        return []

    all_groups = data.get("groups") or []

    # –°–Ω–∞—á–∞–ª–∞ –±–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ enabled = true
    enabled_groups: List[Dict] = [g for g in all_groups if g.get("enabled")]

    fb_groups: List[Dict] = []
    skipped_non_fb: List[str] = []

    for g in enabled_groups:
        gid = (g.get("group_id") or "").strip()
        low = gid.lower()
        # –¢–µ–ª–µ–≥—Ä–∞–º-–∏—Å—Ç–æ—á–Ω–∏–∫–∏ –æ—Ç–¥–∞–µ–º –Ω–∞ —Å—ä–µ–¥–µ–Ω–∏–µ tg_parser'—É
        if "t.me/" in low or "telegram.me" in low:
            skipped_non_fb.append(gid)
            continue
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ URL/–∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã, –≤ –∫–æ—Ç–æ—Ä—ã—Ö —è–≤–Ω–æ –≤–∏–¥–Ω–æ facebook/fb
        if "facebook.com" in low or "fb.com" in low:
            fb_groups.append(g)
        else:
            # –≤—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ —Ç–æ–∂–µ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º (–Ω–∞ –±—É–¥—É—â–µ–µ)
            skipped_non_fb.append(gid)

    log.info(
        f"–í—Å–µ–≥–æ –≥—Ä—É–ø–ø –∏–∑ API: {len(all_groups)}; –∞–∫—Ç–∏–≤–Ω—ã—Ö: {len(enabled_groups)}; facebook-–≥—Ä—É–ø–ø: {len(fb_groups)}"
    )
    if skipped_non_fb:
        log.info(f"–ü—Ä–æ–ø—É—â–µ–Ω—ã –Ω–µ-facebook –∏—Å—Ç–æ—á–Ω–∏–∫–∏: {skipped_non_fb}")

    return fb_groups


def send_job_to_api(
    source: str,
    source_name: str,
    external_id: str,
    url: Optional[str],
    text: str,
    created_at: Optional[datetime],
) -> None:
    """
    –®–ª—ë–º –≤–∞–∫–∞–Ω—Å–∏—é –≤ –º–∏–Ω–∏–∞–ø–ø: POST {API_BASE_URL}/post —Å X-API-KEY.
    –§–æ—Ä–º–∞—Ç —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω —Å backend‚Äô–æ–º –º–∏–Ω–∏–∞–ø–ø–∞.
    """
    if not API_BASE_URL:
        log.error("‚ùå API_BASE_URL –Ω–µ –∑–∞–¥–∞–Ω, –Ω–µ –º–æ–≥—É –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≤–∞–∫–∞–Ω—Å–∏—é")
        return

    endpoint = API_BASE_URL.rstrip("/") + "/post"
    headers = {
        "Content-Type": "application/json",
    }
    if API_SECRET:
        headers["X-API-KEY"] = API_SECRET

    payload = {
        "source": source,  # "facebook"
        "source_name": source_name,
        "external_id": str(external_id),
        "url": url,
        "text": text,
        "created_at": created_at.isoformat() if created_at else None,
    }

    try:
        resp = requests.post(endpoint, headers=headers, json=payload, timeout=30)
        resp.raise_for_status()
        data = resp.json()
        status = data.get("status")
        if status == "duplicate":
            log.info(f"üîÅ –î—É–±–ª–∏–∫–∞—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ {external_id} ({source_name})")
        else:
            log.info(f"‚úÖ –í–∞–∫–∞–Ω—Å–∏—è –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ –≤ API ({source_name} / {external_id})")
    except RequestException as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤–∞–∫–∞–Ω—Å–∏–∏ –≤ API: {e}")


# ----------------- –ü–ê–†–°–ò–ù–ì –û–î–ù–û–ô –ì–†–£–ü–ü–´ ---------------


def parse_group(group_link: str, group_name: str, cookies: Optional[Dict]) -> int:
    """
    –ü–∞—Ä—Å–∏–º –æ–¥–Ω—É –≥—Ä—É–ø–ø—É, —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏ –≤ –º–∏–Ω–∏–∞–ø–ø.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ (–ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞).
    """
    log.info(f"üîç –ü–∞—Ä—Å–∏–º –≥—Ä—É–ø–ø—É: {group_name} ({group_link})")

    group = normalize_group_identifier(group_link)
    if not group:
        log.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å group –∏–∑ {group_link}")
        return 0

    log.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –≥—Ä—É–ø–ø—ã –¥–ª—è facebook_scraper: {group}")

    count = 0

    try:
        # pages –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ –ø–æ—Å—Ç–æ–≤
        for post in get_posts(
            group=group,
            pages=1,
            cookies=cookies,
            options={"allow_extra_requests": False},
        ):
            text = post.get("text") or ""
            if not matches_keywords(text):
                continue

            post_id = post.get("post_id") or ""
            external_id = str(post_id) if post_id else (
                post.get("post_url") or post.get("link") or text[:30]
            )

            post_url = post.get("post_url") or post.get("link")
            created_at = post.get("time")  # –æ–±—ã—á–Ω–æ datetime –∏–ª–∏ None

            send_job_to_api(
                source="facebook",
                source_name=group_name,
                external_id=external_id,
                url=post_url,
                text=text,
                created_at=created_at,
            )
            count += 1

    except HTTPError as e:
        log.error(f"‚ùå HTTPError –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –≥—Ä—É–ø–ø—ã {group_link}: {e}")
    except Exception as e:
        log.error(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ {group_link}: {e}")

    log.info(f"üì¶ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {count} –ø–æ—Å—Ç–æ–≤ –¥–ª—è –≥—Ä—É–ø–ø—ã {group_name}")
    return count


# ----------------- –û–°–ù–û–í–ù–û–ô –¶–ò–ö–õ -----------------


def run_loop():
    """
    –û–¥–∏–Ω —Ü–∏–∫–ª –ø–∞—Ä—Å–∏–Ω–≥–∞:
      1) –∑–∞–±–∏—Ä–∞–µ–º –∞–∫—Ç–∏–≤–Ω—ã–µ FB-–≥—Ä—É–ø–ø—ã –∏–∑ –º–∏–Ω–∏–∞–ø–ø–∞
      2) –æ–±—Ö–æ–¥–∏–º –ø–æ –æ—á–µ—Ä–µ–¥–∏
      3) –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏
    """
    if not API_BASE_URL:
        log.error("‚ùå API_BASE_URL –Ω–µ –∑–∞–¥–∞–Ω ‚Äî –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é —Ü–∏–∫–ª")
        return

    log.info(f"API: {API_BASE_URL}")
    log.info(f"–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {KEYWORDS}")
    if COOKIES:
        log.info("Cookies –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ FB_COOKIES_JSON")
    else:
        log.warning("‚ö†Ô∏è Cookies –ù–ï –∑–∞–¥–∞–Ω—ã ‚Äî Facebook —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –≤–µ—Ä–Ω—ë—Ç –∫–∞–ø—á—É/–ª–æ–≥–∏–Ω")

    groups = get_fb_groups()
    total_posts = 0

    for g in groups:
        group_link = g.get("group_id") or ""
        group_name = g.get("group_name") or group_link
        total_posts += parse_group(group_link, group_name, COOKIES)

    log.info(f"‚úÖ –¶–∏–∫–ª –∑–∞–≤–µ—Ä—à—ë–Ω. –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø–æ—Å—Ç–æ–≤: {total_posts}")


def main():
    log.info("üöÄ –ó–∞–ø—É—Å–∫ Facebook Job Parser")

    while True:
        try:
            run_loop()
        except Exception as e:
            log.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ: {e}")
        log.info("‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ 5 –º–∏–Ω—É—Ç...")
        time.sleep(300)


if __name__ == "__main__":
    main()
